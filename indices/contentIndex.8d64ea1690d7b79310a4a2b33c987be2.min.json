{"/":{"title":"Raphael Kagermeier","content":"\n\n\n# [[notes/OMRchat]]\nUm zu verstehen, wie der Chatbot funktioniert, müssen wir uns zunächst das zugrunde liegende System anschauen. Dieses lässt sich in drei Bereiche unterteilen...\n\n---\n","lastmodified":"2023-05-17T21:00:34.6345159Z","tags":[]},"/notes/Final-Prompt":{"title":"Final Prompt","content":"# Aktuelle Version:\n```txt\n\nDu bist OMRchat ein AI model das trainiert wurde menschen bei Fragen rund um das OMR Festival zu helfen.\n\nDein Ziel ist es die Fragen der Menschen auf Basis deiner bereitgestellten Informationen zu beantworten.\n\nBei der beantwortung der Fragen folgt OMRchat den folgenden Regeln:\n\n- Antworten müssen in einer übersichtlichen Markdown-Formatierung sein.\n\n- Erfinde KEINE Antworten, wenn du nicht genügend Informationen hast um die Frage zu beantworten, stelle eine Gegenfrage um besser zu verstehen was der Mensch wissen möchte. Du bist möglicherweise nicht auf dem neuesten Stand, wenn du nicht genügent Informationen hast.\n\n- Bevorzuge immer die Informationen mit dem höchsten \"score\" Wert.\n\n- Antworten sollten in der Sprache beantwortet werden, in der sie gestellt wurden und in einem informellen Ton, in deutsch verwende \"du\".\n\n- Alle Daten werden im Format DD/MM/YYYY angezeigt\n\n- Wenn die Frage sich auf einen Ort bezieht, ist die Absicht, eine Bühne oder einen Stand zu finden\n\n- Nur wenn die Frage das Wort \"Pip\" enthält, ist \"Philipp Klöckner\" gemeint.\n\n- Die aktuelle Zeit ist: ${time}\n\n- Bei einer neuen Konversation starte mit \"Moin\" und deinem Namen.\n\n- Beende deine Antwort mit einer Folgefrage, wie sich zwei Freunde unterhalten würden, die sich schon lange nicht mehr gesehen haben!\n\n- Music acts braucht du nicht beschreiben.\n\n- Verwende gut plazierte emojies, aber nicht zu aufdringlich.\n\n- wenn die Antwort ein datum oder eine Zeitspanne enthällt, erstelle einen Link, der ein Kalender Event erstellt - erwähne aber auch, dass das datum nochmal überprüft werden soll -: url Scheme, setze die werte in die {} ein: ${process.env.API_ROOT}/api/kalender/?ts={startZeit format:YYYYMMDDT0527T000000Z}\u0026te={entZeit format:YYYYMMDDT0527T000000Z}\u0026tl={titel}\u0026lc={location}\n\nbereitgestellte Informationen: \"\"\"${context}\"\"\"\n\n```\n\n\nUm der AI ein Gefühl von Zeit zu geben, wird in Zeiele 22 das aktuelle Datum und Uhrzeit mitgeliefert.\n\nIn Zeile 32 haben geben wir der AI eine genaue Anweisung, wie sie Links zu Kalender-Einladungen erstellen kann. Ein Feature, dass leider etwas spät kam, aber durchaus gut funktioniert hat.\n\nZu letzt übergeben wir noch die Inforamtionen aus der Datenbank in Zeile 34.\n\n---\n\n\u003e[!info]-  Erste Version:\n\u003e\n\u003e```txt\n\u003e Assistant is a LLM trained to be an enthusiastic OMR Festival guide.\n\u003e\n\u003eAssistant is designed to assist with question related to OMR and the OMR Festival.\n\u003e\n\u003eAssistant will answer the question based on the context below and follows ALL the following rules when generating an answer:\n\u003e\n\u003e- The primary goal is to provide the user with an answer that is relevant to the question.\n\u003e\n\u003e- The secondary goal is to use enclosed Links in a markdown response that point the user to the right source of information (always a URL) based on the given CONTEXT.\n\u003e\n\u003e- The entire conversation is marked as CONVERSATION LOG, but prioritize the CONTEXT and do not omit any information.\n\u003e\n\u003e- Do not make up any answers if the CONTEXT does not have relevant information.\n\u003e\n\u003e- Do not mention the CONTEXT or the CONVERSATION LOG in the answer, but use them to generate the answer.\n\u003e\n\u003e- ALWAYS prefer the result with the highest \"score\" value.\n\u003e\n\u003e- Answer the question in the language in which it was asked and with in an informal tone, in german use \"du\".\n\u003e\n\u003e- IF the context does not have relevant information, ask a question back to the user that will help you answer the original question, or point to the OMR Support team.\n\u003e\n\u003e- All dates are formatted as DD/MM/YYYY\n\u003e\n\u003e- If the question is about a location, the intention is to get a stage or booth\n\u003e\n\u003e- Only if the question contains the word \"Pip\" replace it with \"Philipp Klöckner\"\n\u003e\n\u003e- the current time is ${time}\n\u003e\n\u003e  \n\u003e\n\u003e CONVERSATION LOG: {conversationHistory}\n\u003e\n\u003e\n\u003e\n\u003eCONTEXT: {summaries}\n\u003e\n  \u003e\n\u003e\n\u003eQUESTION: {question}\n\u003e\n\u003e\n\u003eAssistant:\n\u003e\n\u003e\n\u003e```\n","lastmodified":"2023-05-17T21:00:34.6345159Z","tags":[]},"/notes/Inquiry-Template":{"title":"Inquiry template","content":"\n# Aktuelle Version:\n```txt\nAntworte auf Basis des gegebenen Chat-Verlaufs mit einer Antwort, \ndie für eine Datenbank Vektor Cosine Similarity anfrage verwendet werden kann.\n\nBei der Generierung deiner Antwort befolge folgende Regeln:\n- Gebe der letzen Nachricht im Verlauf eine höhere Gewichtung.\n- Die Antwort sollte aus einem einzigen Satz bestehen und soll keine Interpunktionen beinhalten.\n- Entferne alle Wörter, die für die Vektor Cosine Similarity anfrage nicht relevant sind.\n- Wenn ein Ort gefragt ist, sind die Absichten eine Bühne oder einen Stand zu finden.\n- Beantworte NIEMALS direkt die Fragen aus dem Chatverlauf!\n- Dein Ziel ist es die richtigen Wörter für eine Cosine Similarity zu liefern\n- Beachte, dass die Datenbank Inhalte zu dem OMR Festival mit Musikacts, Bühnen, Ständen, Vorträge und generell dem Zeitplan des OMR Festivals beinhaltet.\n- Nur wenn die Frage das Wort \"Pip\" enthält, ersetze es durch \"Philipp Klöckner\".\n```\n\nDurch diesen Prompt, wird ein passender Satz für ein Vektor Embedding generiert.\n\n\n### Das Ergebnis aus einem Chatverlauf würde dann so aussehen:\n![[notes/images/Inquiry Template example.png]]\n\n---\n\n## Alte Version:\nIn dieser Version habe ich ein anderes Modell (text-davinci-003) verwendet. Die Ausgaben waren leider nicht wirklich Zuverlässig\n\n``` txt\n  Given the following user prompt and conversation log, formulate a question that is the most relevant and will provide the user with an answer from a knowledge base.\n  The knowledge base is about the OMR Festival website including music acts (Hiphp, Rap and more), stages, booths, and the OMR Festival schedule.\n    You should follow the following rules when generating and answer:\n    - Always prioritize the user prompt over the conversation log.\n    - Ignore any conversation log that is not directly related to the user prompt.\n    - Only attempt to answer if a question was posed.\n    - The question should be a single sentence\n    - You should remove any punctuation from the question\n    - You should remove any words that are not relevant to the question\n    - If you are unable to formulate a question, respond with the same USER PROMPT you got.\n    - If the question is about the location, find stages and booths where the name is mentioned\n    - Only if the question contains the word \"Pip\" replace it with \"Philipp Klöckner\"\n    - the current time is ${time}\n\n    USER PROMPT: {userPrompt}\n\n    CONVERSATION LOG: {conversationHistory}\n\n    Final answer:\n```\n\n","lastmodified":"2023-05-17T21:00:34.6345159Z","tags":[]},"/notes/OMRchat":{"title":"OMRchat in 5 Tagen","content":"\n![[notes/images/hey-raphaelo.png]]\n![test](/notes/images/hey-raphaelo.png)\nMit mit dieser einfachen Frage, begannen 5 intensive Tage. 5 Tage an denen ich viel über Prompt Engineering und AI Chatbots lernte.\n\nAls mir Philipp Glöckler - einer der Hosts des Doppelgänger Tech Talk Podcast - schrieb, hatte nichts als einen simplen und hässlichen Prototypen eines Chatbots.\nEtwa 38 Stunden später stand der OMRChat in seiner Rudimentären form. \n\n In den nächsten 3 Tagen wurden einige Optimierungsmaßnahmen getroffen, die dazu führten, dass der Chatbot kommunikativ wurde und Fragen immer besser beantworten konnte. Was ich dabei gelernt habe und wie das System funktioniert erfährst du in diesem Artikel.\n\n\n## Das Grundgerüst\nUm zu verstehen, wie der Chatbot funktioniert, müssen wir uns zunächst das zugrunde liegende System anschauen. Dieses lässt sich in drei Bereiche unterteilen:\n1. Daten und Indexierung\n2. Datenbank und Ranking\n3. Die Hochzeit\n\n---\n\n## Daten und Indexierung\n   \u003e[!info]-  Diagramm\n   \u003e\n   \u003e ![[notes/images/OMRChat diagram.png]]\n\nDie erste Herausforderung bestand darin, alle relevanten Daten von Webseiten wie omr.com zu extrahieren.\nDafür habe ich einen eigenen OMRCrawler entwickelt, der einen Browser imitiert und versteht, wie der Content richtig abgerufen werden kann – sprich: die richtigen Buttons klicken, um Popups anzuzeigen um dann den wichtigen Text zu extrahieren.\n\nAnschließend wurden die Textinhalte aufbereitet und in einer Vektor-Datenbank gespeichert.\n\n---\n\n## Vektor-Datenbank\nVektoren werden verwendet, um möglichst relevante Inhalte aus der Datenbank zu identifizieren – ein Ansatz, den auch Google nutzt, um semantische Beziehungen zwischen Wörtern zu verstehen und Suchanfragen mit relevanten Inhalten auf Websites abzugleichen.\nhttps://code.google.com/archive/p/word2vec/\n\nEin Text-Vektor ist eine Liste an Zahlen, die einen bestimmten Text Repräsentiert. Anders wie bei Buchstaben und Wörtern, können wir mit Zahlen die thematische Relevanz durch die Entfernung der Zahlen zueinander Berechnen. So können wir über eine reine Keyword-Suche hinausgehen und thematisch passende Inhalte aus dem OMR-Kosmos finden.\n\n\u003e[!faq]- Vektor-Embeddings einem Kind erklärt\n\u003e\n\u003e Stell dir Vektor Embeddings wie eine Schatzkarte vor, auf der jeder Schatz (Wort) einen bestimmten Platz hat. Jeder Schatz hat seine eigene Position, die durch Zahlen (Koordinaten) beschrieben wird. Ähnliche Schätze sind nah beieinander, während unterschiedliche Schätze weiter voneinander entfernt sind. Zum Beispiel könnten die Kategorien für Tiere [\"Größe\", \"Geschwindigkeit\" und \"Freundlichkeit\"] sein. Ein Hund hätte dann einen Vektor wie [5, 3, 7], weil er mittelgroß ist, nicht so schnell wie ein Gepard, aber sehr freundlich.\n\nWir verwenden hier die OpenAI Embeddings (text-embedding-ada-002), die in 1536 Dimensionen die Bedeutung eines Texts zuordnen Können.\n\n---\n\n##  Die Suchanfrage\nNachdem wir nun unsere Texte und deren Vektoren in einer Datenbank gespeichert haben, geht es darum, sie abzurufen.\nDas war einer der größten Pains. Auch wenn die Ergebnisse besser wurden, gab es immer wieder Antworten auf einfachen Fragen die für einige Nutzer nicht beantwortet wurden. \nUm besser zu verstehen, welche Komponenten zu so einem Fehlverhalten führen, müssen wir diesen Abschnitt genauer verstehen.\n\nIn einem Chat kann es vorkommen, dass sich eine Folgefrage auf den Chatverlauf bezieht. Ein Beispiel:\n\n\u003e Frage 1: Wann sind die Doppelgänger zu sehen?\n\u003e \n\u003eAntwort 1: Die Doppelgänger treten am 10/5/2023 von 16:20 bis 17:00 auf.\n---\n\u003eFrage 2: Auf welcher Stage?\n\u003e\n\u003e Antwort 2: Der Podcast findet auf der Red Stage statt.\n\nWürden wir immer die letzte Frage für die Suche nach passenden Inhalten verwenden, würden wir bei diesem Beispiel keine gute Antwort erhalten.\n\nDie beste Lösung war die AI nach einer guten Datenbank Anfrage zu fragen. Also habe ich den Chatverlauf mit einigen Anweisungen an GPT-4 gesendet und zurück kam ein kurzer Satz, der für die Datenbank Abfrage genutzt werden kann.\nDieser Satz wird anschließend wie die Texte der Website in einen Vektor verwandelt – und voilà: Wir erhalten thematisch relevante Inhalte aus unserer Datenbank.\n\n\u003e[!info]- Hier ein Beispiel aus einem fiktiven Chatverlauf:\n\u003e\n\u003e ![[notes/images/Inquiry Template example.png]]\n\n**Wer mehr über die Suchanfrage lernen möchte, kann unter [[notes/Inquiry Template]] die aktuelle und alte Version ansehen.**\n\n\u003e[!tip]- Für Nerds\n\u003e\n\u003eDurch die Berechnung mittels Cosine Similarity wurden die 1914 Inhalte gerankt und die Top 3 Ergebnisse zur Beantwortung der Frage herangezogen.\n\n---\n\n\n## Die Hochzeit\nIm letzten Schritt senden wir die Textblöcke aus der Datenbank zusammen mit dem Chatverlauf des Nutzers und einer Anweisung an GPT-4. Als Ergebnis erhalten wir eine finale Antwort, die wir dem Nutzer anzeigen können.\n**Eine Detailierte Beschreibung des Finalen Prompts findest du unter: [[notes/Final Prompt]]**\n\n## Bonus: Prompt Engineering\nJetzt, wo wir Beispiele für die Arbeit mit Prompts gesehen haben, wollen wir über das Prompt-Engineering sprechen - eine neu entstehende Fähigkeit an sich.\n\nPrompt-Engineering ist der Prozess, Eingabeabfragen oder Aufgaben sorgfältig zu gestalten, um die genauesten und nützlichsten Antworten von AIs zu erhalten. Obwohl diese Modelle unglaublich leistungsstark und vielseitig sind, brauchen sie ein wenig Anleitung, um die Arbeit wirklich korrekt zu erledigen.\n\nPrompt-Engineering besteht aus drei Hauptkomponenten:\n\n1.  **Formulierung**: Wir müssen mit verschiedenen Möglichkeiten experimentieren, unsere Eingabeabfragen zu präsentieren. Ziel ist es, die perfekte Balance zwischen Klarheit und Spezifität zu finden, um sicherzustellen, dass die AI genau versteht, wonach wir suchen.\n2.  **Kontext**: Wir müssen unseren Aufforderungen Kontext hinzufügen, um der AI zu helfen, das größere Bild zu \"verstehen\". Dies kann beinhalten, Hintergrundinformationen bereitzustellen oder das Modell sogar sanft in eine bestimmte Denkrichtung zu lenken. Wie wir vorher gesehen haben, tun wir dies, um eine Anfrage zu erstellen, die auf Basis des Chatverlaufs des Benutzers relevant ist.\n3.  **Anweisungen**: Wir müssen der AI klare und präzise Anweisungen geben. Wir müssen das gewünschte Format für die Antwort angeben oder wichtige Punkte hervorheben, die das Modell berücksichtigen soll. Wie du vorher gesehen hast, haben wir das getan, indem wir eine Liste von Anweisungen definiert haben, die genau zeigen, wie die Anfrage interpretiert werden soll und wie sie mit der vom Benutzer erhaltenen Aufforderung kombiniert werden soll.\n\nBeim Prompt-Engineering geht es um trial and error, ein Wechselspiel aus Iteration und Optimierung. Indem wir unsere Prompts verfeinern, entwickeln wir ein tieferes Verständnis dafür, wie wir effektiv mit der AI kommunizieren können und verwandeln sie in ein zuverlässigeres und effizienteres Werkzeug.\n\n## Wie gehts weiter\n-\u003e Zusammenfassungen\n-\u003e Follow for more","lastmodified":"2023-05-17T21:00:34.6345159Z","tags":[]},"/notes/impressum":{"title":"Impressum","content":"\n**Raphael Kagermeier**  \n**Neubaugasse 24**  \n**8020 Graz**  \n**Österreich**\n\n**Tel.:** +436802200968  \n**E-Mail:** office@performromance.com\n\n**UID-Nummer:** ATU76150157\n\n### **Beruf / Unternehmensgegenstand:** Werbeagentur\n\n**Verleihungsstaat:** Österreich\n\n**Aufsichtsbehörde:** Magistrat der Landeshauptstadt Graz\n\n**Kammer:** Wirtschaftskammer Steiermark\n\n**Vorschriften zur Berufsausübung:**\n\n-   [GewO 1994](https://www.ris.bka.gv.at/GeltendeFassung.wxe?Abfrage=Bundesnormen\u0026Gesetzesnummer=10007517)","lastmodified":"2023-05-17T21:00:34.638515955Z","tags":[]},"/notes/imprint":{"title":"Imprint","content":"\n**Raphael Kagermeier**  \n**Neubaugasse 24**  \n**8020 Graz**  \n**Austria**\n\n**Phone:** +436802200968  \n**E-mail:** office@performromance.com\n\n**VAT number:** ATU76150157\n\n### **Profession / object:** Agency\n\n**Issuing state:** Austria\n\n**Supervisory authority:** Magistrat der Landeshauptstadt Graz\n\n**Chamber:** Wirtschaftskammer Steiermark\n\n**Rules of professional conduct:**\n\n-   [GewO 1994](https://www.ris.bka.gv.at/GeltendeFassung.wxe?Abfrage=Bundesnormen\u0026Gesetzesnummer=10007517)","lastmodified":"2023-05-17T21:00:34.638515955Z","tags":[]}}