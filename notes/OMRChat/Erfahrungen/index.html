<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="Mit dieser einfachen Frage begannen fünf intensive Tage, in denen ich viel über Prompt Engineering und KI Chatbots lernte. Als mir Philipp Glöckler, einer der Hosts des Doppelgänger Tech Talk Podcast schrieb, hatte ich nichts weiter als einen schlichten und wenig ansprechenden Prototypen eines Chatbots."><meta property="og:title" content="Erfahrungen und Erkentnisse auf dem Weg zum OMRChat."><meta property="og:description" content="Mit dieser einfachen Frage begannen fünf intensive Tage, in denen ich viel über Prompt Engineering und KI Chatbots lernte. Als mir Philipp Glöckler, einer der Hosts des Doppelgänger Tech Talk Podcast schrieb, hatte ich nichts weiter als einen schlichten und wenig ansprechenden Prototypen eines Chatbots."><meta property="og:type" content="website"><meta property="og:image" content="https://raphael-kagermeier.github.io/blog/icon.png"><meta property="og:url" content="https://raphael-kagermeier.github.io/blog/notes/OMRChat/Erfahrungen/"><meta property="og:width" content="200"><meta property="og:height" content="200"><meta name=twitter:card content="summary"><meta name=twitter:title content="Erfahrungen und Erkentnisse auf dem Weg zum OMRChat."><meta name=twitter:description content="Mit dieser einfachen Frage begannen fünf intensive Tage, in denen ich viel über Prompt Engineering und KI Chatbots lernte. Als mir Philipp Glöckler, einer der Hosts des Doppelgänger Tech Talk Podcast schrieb, hatte ich nichts weiter als einen schlichten und wenig ansprechenden Prototypen eines Chatbots."><script>var _paq=window._paq=window._paq||[];_paq.push(["disableCookies"]),_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){t="https://analyze.performromance.com/",_paq.push(["setTrackerUrl",t+"matomo.php"]),_paq.push(["setSiteId","26"]);var t,n=document,e=n.createElement("script"),s=n.getElementsByTagName("script")[0];e.async=!0,e.src=t+"matomo.js",s.parentNode.insertBefore(e,s)}()</script><meta name=twitter:image content="https://raphael-kagermeier.github.io/blog/icon.png"><title>Erfahrungen und Erkentnisse auf dem Weg zum OMRChat.</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://raphael-kagermeier.github.io/blog//icon.png><link href=https://raphael-kagermeier.github.io/blog/styles.ded122f46c73efb0e4e080de1a9f920d.min.css rel=stylesheet><link href=https://raphael-kagermeier.github.io/blog/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=//unpkg.com/alpinejs defer></script>
<script src=https://raphael-kagermeier.github.io/blog/js/darkmode.0c3686ec2ade2ad6c8f789f7d473f725.min.js></script>
<script src=https://raphael-kagermeier.github.io/blog/js/util.00639692264b21bc3ee219733d38a8be.min.js></script>
<link rel=preload href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css as=style onload='this.onload=null,this.rel="stylesheet"' integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/core@1.2.1></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/dom@1.2.1></script>
<script defer src=https://raphael-kagermeier.github.io/blog/js/popover.aa9bc99c7c38d3ae9538f218f1416adb.min.js></script>
<script defer src=https://raphael-kagermeier.github.io/blog/js/code-title.ce4a43f09239a9efb48fee342e8ef2df.min.js></script>
<script defer src=https://raphael-kagermeier.github.io/blog/js/clipboard.2913da76d3cb21c5deaa4bae7da38c9f.min.js></script>
<script defer src=https://raphael-kagermeier.github.io/blog/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const SEARCH_ENABLED=!1,LATEX_ENABLED=!0,PRODUCTION=!0,BASE_URL="https://raphael-kagermeier.github.io/blog/",fetchData=Promise.all([fetch("https://raphael-kagermeier.github.io/blog/indices/linkIndex.b049578ad89fcd3406db6b8c37ccc003.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://raphael-kagermeier.github.io/blog/indices/contentIndex.0da8a27ee5ffbe2b6306adf1d6a4bd52.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,i=t==n;addCopyButtons(),addCollapsibleCallouts(),initPopover("https://raphael-kagermeier.github.io/blog",!0);function s(n){const e=n.target,t=e.className.split(" "),s=t.includes("broken"),o=t.includes("internal-link");plausible("Link Click",{props:{href:e.href,broken:s,internal:o,graph:!1}})}const o=document.querySelectorAll("a");for(link of o)link.className.includes("root-title")&&link.addEventListener("click",s,{once:!0})},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'’':"'"},throwOnError:!1})}</script><script>window.Million={navigate:e=>window.location.href=e,prefetch:()=>{}},window.addEventListener("DOMContentLoaded",()=>{init(),render()})</script><script defer data-domain=raphael-kagermeier.github.io/blog src=https://plausible.io/js/script.js></script>
<script>window.plausible=window.plausible||function(){(window.plausible.q=window.plausible.q||[]).push(arguments)}</script><script>window.onload=function(){var e=document.getElementsByClassName("typewriter");for(let n=0;n<e.length;n++){let s=0,o=e[n].getAttribute("data-text"),i=parseInt(e[n].getAttribute("data-speed")),a=parseInt(e[n].getAttribute("data-delay"));function t(){s<o.length?(e[n].innerHTML+=o.charAt(s),s++,setTimeout(t,i)):e[n].classList.remove("typewriter-cursor")}setTimeout(function(){e[n].classList.add("typewriter-cursor"),t()},a)}}</script></head><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://raphael-kagermeier.github.io/blog/js/full-text-search.e6e2e0c213187ca0c703d6e2c7a77fcd.min.js></script><div class=singlePage><header><h1 id=page-title><a class=root-title href=https://raphael-kagermeier.github.io/blog/>🪴</a>
<span class=logo__cursor></span></h1><div class=spacer></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>Erfahrungen und Erkentnisse auf dem Weg zum OMRChat.</h1><p class=meta></p><ul class=tags></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#das-grundgerüst>Das Grundgerüst</a></li><li><a href=#daten-und-indexierung>Daten und Indexierung</a></li><li><a href=#vektor-datenbank>Vektor-Datenbank</a></li><li><a href=#die-suchanfrage>Die Suchanfrage</a></li><li><a href=#die-hochzeit>Die Hochzeit</a></li><li><a href=#bonus-prompt-engineering>Bonus: Prompt Engineering</a></li><li><a href=#wie-gehts-weiter>Wie geht&rsquo;s weiter?</a></li></ol></nav></details></aside><p><img src=https://raphael-kagermeier.github.io/blog//notes/images/hey-raphaelo.png width=auto alt="Hey Raphaelo">
Mit dieser einfachen Frage begannen fünf intensive Tage, in denen ich viel über Prompt Engineering und KI Chatbots lernte. Als mir Philipp Glöckler, einer der Hosts des
<a href=https://www.doppelgaenger.io/ rel=noopener>Doppelgänger Tech Talk Podcast</a> schrieb, hatte ich nichts weiter als einen schlichten und wenig ansprechenden Prototypen eines Chatbots. Etwa 38 Stunden später stand der OMRChat in seiner rudimentären Form. In den darauffolgenden drei Tagen wurden weitere Optimierungen vorgenommen, sodass der Chatbot immer besser kommunizieren und Fragen beantworten konnte. In diesem Artikel erfährst du, wie das System dahinter funktioniert und vorallem was ich dabei gelernt habe.</p><a href=#das-grundgerüst><h2 id=das-grundgerüst><span class=hanchor arialabel=Anchor># </span>Das Grundgerüst</h2></a><p>Um den Ablauf des Chatbots zu verstehen, sollten wir uns zuerst die grundlegende Struktur ansehen. Diese gliedert sich in drei Bereiche:</p><ol><li>Daten und Indexierung</li><li>Datenbank und Ranking</li><li>Die Hochzeit</li></ol><p><strong>Eine detaillierte Darstellung findest du in diesem Diagramm:</strong></p><blockquote class="callout-collapsible callout-collapsed info-callout"><p>Diagramm</p><p><img src=https://raphael-kagermeier.github.io/blog//notes/images/OMRChat-diagram.png width=auto alt=diagram></p></blockquote><hr><a href=#daten-und-indexierung><h2 id=daten-und-indexierung><span class=hanchor arialabel=Anchor># </span>Daten und Indexierung</h2></a><p>Die erste Herausforderung bestand darin, alle relevanten Daten von Webseiten wie omr.com zu extrahieren. Dafür entwickelte ich einen OMRCrawler, der einen Browser imitiert und versteht, wie der Content richtig abgerufen werden kann – sprich: Auf die richtigen Buttons klicken, um Popups anzuzeigen und dann den richtigen Text zu kopieren. Anschließend werden die Textinhalte aufbereitet und in einer Vektor-Datenbank gespeichert.</p><hr><a href=#vektor-datenbank><h2 id=vektor-datenbank><span class=hanchor arialabel=Anchor># </span>Vektor-Datenbank</h2></a><p>In der Vektor-Datenbank sind die mit Hilfe von Embeddings aufbereiteten Texte in Form von Vektoren gespeichert.</p><p>Doch was sind Vektoren in diesem Kontext und wozu werden sie verwendet?</p><p>Ein Vektor ist eine Liste von Zahlen, welche aus dem jeweiligen Text generiert wird. Der eintscheidende Vorteil dieser Umwandlung liegt darin, dass sich Zahlen deutlich besser eignen um Texte miteinander zu vergleichen. Die Distanz zwischen zwei Vektoren ist dabei ein Indikator, wie ähnlich zwei Texte und dessen Inhalte sind.</p><p>Diese Eigenschaft wird in der Anwendung des OMR-Chatbots genutzt, um auf Fragen des Nutzers alle relevanten Texte aus der Vektor-Datenbank für den weiteren Prozess zu sammeln und um schlussendlich auch eine relevante (und richtige) Antwort geben zu können.</p><p>Um Vektoren etwas anschaulicher zu erklären noch ein kleines Beispiel:
Man könnte einen Vektor zur Klassifizierung von Tieren entwerfen, welcher jeder Tierart einen 2-Dimensionalen Vektor zuordnet, z.B.: Größe und Geschwindigkeit. Ein Hund hätte dann einen Vektor von [5, 2], weil er mittelgroß ist, aber nicht sonderlich schnell. Ein Elefant hätte einen Vektor von [8, 2], der Esel [7, 1] und eine Katze von [5, 3].</p><p><img src=https://raphael-kagermeier.github.io/blog//notes/images/Vektor.png width=auto alt="animal vektor"></p><p>Mit dieser Darstellung können die verschiedenen Tierarten leicht miteinander verglichen werden. Auch hier lässt die Distanz zwischen den Vektoren zweier Tierarten auf ihre Ähnlichkeit schließen. Beispielsweise ist der Hund der Katze recht ähnlich, jedoch weit weniger als dem Elefanten.</p><p>In unserem Beispiel hat der Vektor nur zwei Dimensionen. Text-Vektoren, die u.a.
<a href=https://code.google.com/archive/p/word2vec/ rel=noopener>bei Google</a> zum Einsatz kommen, sind deutlich umfangreicher, um semantische Beziehungen zwischen Texten zu verstehen.</p><p>Im Fall des OMRChat habe ich mich auf das Modell von OpenAI (text-embedding-ada-002) verlassen. Dieses umfasst 1536 Dimensionen und ist daher ideal für die Textsuche.</p><hr><a href=#die-suchanfrage><h2 id=die-suchanfrage><span class=hanchor arialabel=Anchor># </span>Die Suchanfrage</h2></a><p>Nachdem wir nun unsere Texte und deren Vektoren in einer Datenbank gespeichert haben, geht es darum sie abzurufen.
Das war eine der größten Herausforderungen. Auch wenn die Ergebnisse besser wurden, kam es immer wieder zu unbeantworteten Fragen. Um besser zu verstehen, was zu solch einem Fehlverhalten führen kann, müssen wir auf diesen Abschnitt genauer eingehen.</p><p>In einem Chat kann es vorkommen, dass sich eine Folgefrage auf den Chatverlauf bezieht. Ein Beispiel:</p><blockquote class=question-callout><p>Frage 1: Wann sind die Doppelgänger zu sehen?</p><p>Die Doppelgänger treten am 10/5/2023 von 16:20 bis 17:00 auf.</p></blockquote><blockquote class=question-callout><p>Frage 2: Auf welcher Stage?</p><p>Der Podcast findet auf der Red Stage statt.</p></blockquote><p>Wenn wir stets die letzte Frage für die Suche nach passenden Inhalten heranziehen würden, bekämen wir in diesem Beispiel keine zufriedenstellende Antwort.</p><hr><p>Die beste Lösung bestand darin, die KI um eine geeignete Datenbankabfrage zu bitten. Daher sende ich den Chatverlauf zusammen mit einigen Anweisungen an GPT-4, um aus dem Kontext heraus einen kompakten Satz für die Datenbankabfrage generieren zu lassen. Dieser Satz wird - wie die Texte der Website - in einen Vektor umgewandelt und mit den Vektoren aus der Datenbank verglichen.</p><blockquote class=info-callout><p>Hier ein Beispiel aus einem fiktiven Chatverlauf:</p><p><img src=https://raphael-kagermeier.github.io/blog//notes/images/Inquiry-Template.png width=auto alt="inquiry template"></p></blockquote><p>Durch diesen &ldquo;Frage-Vektor&rdquo; ist es nun möglich, relevante Inhalte aus der Datenbak zu entnehmen.</p><p><strong>Wer mehr über diese Suchanfrage erfahren möchte, findet weitere Infos unter <a href=/blog/notes/OMRChat/Inquiry-Template rel=noopener class=internal-link data-src=/blog/notes/OMRChat/Inquiry-Template>Inquiry Template</a></strong></p><blockquote class="callout-collapsible callout-collapsed tip-callout"><p>Für Nerds</p><p>Durch die Distanz-Berechnung mittels Cosine Similarity wurden die 1914 Inhalte gerankt und die Top 3 Ergebnisse zur Beantwortung der Frage herangezogen.</p></blockquote><hr><a href=#die-hochzeit><h2 id=die-hochzeit><span class=hanchor arialabel=Anchor># </span>Die Hochzeit</h2></a><p>Im letzten Schritt sende ich die Textblöcke aus der Datenbank, zusammen mit dem Chatverlauf des Nutzers und einer Anweisung an GPT-4. Als Ergebnis erhalten wir eine finale Antwort, welche wir dem Nutzer anzeigen können. Eine detaillierte Beschreibung des finalen Prompts findest du unter: <a href=/blog/notes/OMRChat/Final-Prompt rel=noopener class=internal-link data-src=/blog/notes/OMRChat/Final-Prompt>Final Prompt</a></p><hr><a href=#bonus-prompt-engineering><h2 id=bonus-prompt-engineering><span class=hanchor arialabel=Anchor># </span>Bonus: Prompt Engineering</h2></a><p>Jetzt, wo wir Beispiele für die Arbeit mit Prompts gesehen haben, möchte ich noch kurz über Prompt-Engineering sprechen – eine neu entstehende Fähigkeit an sich.</p><p>Prompt-Engineering ist der Prozess, Prompts oder Aufgaben sorgfältig zu definieren, um die genauesten und nützlichsten Antworten von der KI zu erhalten. Obwohl diese Modelle unglaublich leistungsstark und vielseitig sind, brauchen sie aktuell eine Anleitung, um die Arbeit wirklich korrekt zu erledigen.</p><p>Prompt-Engineering besteht aus drei Hauptkomponenten:</p><ol><li><strong>Formulierung</strong>: Wir müssen mit verschiedenen Möglichkeiten experimentieren, um unsere Prompts zu präsentieren. Ziel ist es, die perfekte Balance zwischen Klarheit und Interpretation zu finden, um sicherzustellen, dass die KI genau versteht, wonach wir suchen.</li><li><strong>Kontext</strong>: Wir müssen unseren Aufforderungen Kontext hinzufügen, um der AI zu helfen, das größere Bild zu &ldquo;verstehen&rdquo;. Dies kann beinhalten, Hintergrundinformationen bereitzustellen, oder das Modell sogar sanft in eine bestimmte Denkrichtung zu lenken.</li><li><strong>Anweisungen</strong>: Wir müssen der KI präzise Anweisungen geben. Wie du in dem <a href=/blog/notes/OMRChat/Inquiry-Template rel=noopener class=internal-link data-src=/blog/notes/OMRChat/Inquiry-Template>Inquiry Template</a> gesehen hast, haben wir eine Liste von Anweisungen definiert, die genau zeigen, wie die Anfrage interpretiert werden soll und wie sie mit der vom Nutzer erhaltenen Frage kombiniert werden soll.</li></ol><p>Beim Prompt-Engineering geht es um Trial and Error, ein Wechselspiel aus Iteration und Optimierung. Indem wir unsere Prompts verfeinern, entwickeln wir ein tieferes Verständnis dafür, wie wir effektiv mit der KI kommunizieren können und verwandeln sie in ein zuverlässigeres und effizienteres Werkzeug.</p><hr><a href=#wie-gehts-weiter><h2 id=wie-gehts-weiter><span class=hanchor arialabel=Anchor># </span>Wie geht&rsquo;s weiter?</h2></a><p>Das OMR Festival 2023 ist nun vorüber und somit auch das exponentielle Wachstum des OMRChat.</p><p>Obwohl das Projekt den FestivalbesucherInnen dabei half, spannende Vorträge und Veranstaltungen zu entdecken, fällt es bei Events dieser Größe oft schwer, alle geplanten Acts zu besuchen.</p><p>Zwar veröffentlicht OMR einige Vorträge nach und nach auf YouTube, doch es ist oft schwierig, die Zeit zu finden, diese in Ruhe anzuschauen und etwas daraus mitzunehmen.</p><p><strong>Leben wir nicht im Zeitalter der Effizienz?</strong></p><p>Warum fragen wir nicht die KI, nach der Quintessenz aus Pip&rsquo;s (Philipp Klöckner) OMR Keynote?</p><blockquote class=question-callout><p>Was ist die Quintessenz aus Pip&rsquo;s Talk über das Zeitalter der Effizienz?</p><p>🌐💼📉</p><p>Die Welt kämpft mit einem Produktivitätsproblem, das durch ineffiziente Tech-Unternehmen wie Google und Facebook verschärft wird. Künstliche Intelligenz (KI) hat das Potenzial, die Produktivität und das Wirtschaftswachstum zu steigern, indem sie Umsatz generiert und neue Produkte und Dienstleistungen ermöglicht. KI wird Arbeitsplätze schaffen und ersetzen, wobei vor allem kreative, hochbezahlte und hochgebildete Berufe betroffen sind.</p><p>🤖💪📈</p><p>Es gibt jedoch Herausforderungen wie Content-Explosion, Vertrauenskrise, gesellschaftliche Spaltungen, Verlust von Heterogenität und Verifikationsprobleme. Lösungen müssen gefunden werden, um die KI optimal zu nutzen. Generative KI-Modelle wie GPT-3 von OpenAI könnten viele Branchen beeinflussen, darunter Bildung, Marketing und Softwareentwicklung.</p><p>🚀🧠🇩🇪</p><p>Der Wettlauf um KI umfasst nicht nur die Modelle selbst, sondern auch Daten, Hardware und Distribution. Große Tech-Konzerne sind im Vorteil, aber generative KI wird sich weiterentwickeln und möglicherweise eine Verschiebung bewirken. Deutschland hat aufgrund der vielen Entwickler und KI-Institute im Land Potenzial, erfolgreich in der KI-Branche zu sein.</p></blockquote><p>Oder</p><blockquote class=question-callout><p>Fasse den Talk von Jeremy in seinem Style Zusammen</p><p>Hey Leute, hier ist die Zusammenfassung, Alter! Jeremy spricht über das Gewinner-Mindset, Autosuggestionen und sich selbst zur Marke machen. Er betont, wie wichtig es ist, sich immer wie ein Gewinner zu fühlen und in einer hohen Energie zu sein, um Aufmerksamkeit zu erregen. Er erklärt, wie er auf TikTok erfolgreich ist und wie er sein Geld verdient, vor allem durch den Verkauf seiner eigenen Produkte. Also, Leute, denkt immer an euer Gewinnermindset, habt geile Autosuggestionen und macht aus euch eine krasse Brand! Power, Power, Kraft, Power, Strength!</p></blockquote></article><hr><div id=contact_buttons><footer><p>Raphael Kagermeier © 2023</p><ul><li><a href=https://raphael-kagermeier.github.io/blog/>Home</a></li><li><a href=https://twitter.com/raph_is>Twitter</a></li><li><a href=https://www.linkedin.com/in/raphael-kagermeier/>Linkedin</a></li><li><a href=/notes/imprint>Imprint</a></li></ul></footer></div></div></body></html>