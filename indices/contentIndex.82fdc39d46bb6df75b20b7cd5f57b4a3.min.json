{"/":{"title":"Raphael Kagermeier","content":"\n\u003cdiv style=\"display: inline-flex;\"\u003e\n\u003ch1 class=\"enter-wink\" style=\"margin-right:5px\"\u003eüëã\u003c/h1\u003e \u003ch1 class=\"typewriter\" data-text=\"Hi,\" data-speed=\"100\" data-delay=\"500\"\u003e\u003c/h1\u003e\n\u003c/div\u003e\n\n\u003cp class=\"typewriter\" data-speed=\"5\" data-delay=\"1000\" data-text=\"Ich bin Raphael. Meine Leidenschaft f√ºr Softwareentwicklung, Marketing und seit zwei Jahren auch KI hat mich zu einigen spannenden Projekten und Unternehmen gef√ºhrt.\"\u003e\u003c/p\u003e\n\u003cp class=\"typewriter\" data-speed=\"5\" data-delay=\"3000\" data-text=\"Getrieben von Neugierde habe ich mit 16 Jahren einen E-Commerce-Shop gestartet, ein Ad-Tech-SaaS entwickelt und anschlie√üend eine Performance-Marketing-Agentur aufgebaut.\"\u003e\u003c/p\u003e\n\u003cp class=\"typewriter\" data-speed=\"5\" data-delay=\"5000\" data-text=\"Falls dich eines dieser Themen interessiert, erf√§hrst du hier meine Erkenntnisse, bew√§hrte Praktiken und manchmal auch, was sonst noch so los ist!\"\u003e\u003c/p\u003e\n\n\u003cdiv style=\"margin-top: 5rem\" x-data=\"{show:false}\" x-show=\"show\" x-transition.scale.origin.top x-init=\"setTimeout(() =\u003e show = true,7000)\"\u003e\n\n# üïêüìÑ Letzer Beitrag\n\n### [OMRChat Erfahrungen](notes/OMRChat/Erfahrungen)\nUm den Ablauf des Chatbots zu verstehen, sollten wir uns zuerst die grundlegende Struktur ansehen. Diese gliedert sich in drei Bereiche...\n\n---\n\n\u003c/div\u003e","lastmodified":"2023-05-26T19:19:53.377621153Z","tags":[]},"/notes/OMRChat/Erfahrungen":{"title":"Erfahrungen und Erkentnisse auf dem Weg zum OMRChat.","content":"\n![Hey Raphaelo](/notes/images/hey-raphaelo.png)\nMit einer einfachen Frage begannen f√ºnf intensive Tage, in denen ich viel √ºber Prompt Engineering und AI Chatbots lernte. Als mir Philipp Gl√∂ckler, einer der Hosts des [Doppelg√§nger Tech Talk Podcast](https://www.doppelgaenger.io/) schrieb, hatte ich nichts weiter als einen schlichten und wenig ansprechenden Prototypen eines Chatbots. Etwa 38 Stunden sp√§ter stand der OMRChat in seiner rudiment√§ren Form. In den darauffolgenden drei Tagen wurden weitere Optimierungen vorgenommen, sodass der Chatbot immer besser kommunizierte und Fragen beantworten konnte. In diesem Artikel erf√§hrst du, was ich dabei gelernt habe und wie das System funktioniert.\n\n## Das Grundger√ºst\nUm den Ablauf des Chatbots zu verstehen, sollten wir uns zuerst die grundlegende Struktur ansehen. Diese gliedert sich in drei Bereiche:\n\n1. Daten und Indexierung\n2. Datenbank und Ranking\n3. Die Hochzeit\n\n**Eine detaillierte Darstellung findest du in diesem Diagramm:**\n\n\u003e[!info]- Diagramm\n\u003e\n\u003e ![diagram](notes/images/OMRChat-diagram.png)\n\n---\n\n## Daten und Indexierung\n\nDie erste Herausforderung bestand darin, alle relevanten Daten von Webseiten wie omr.com zu extrahieren. Daf√ºr entwickelte ich einen OMRCrawler, der einen Browser imitiert und versteht, wie der Content richtig abgerufen werden kann ‚Äì sprich: Auf die richtigen Buttons klicken, um Popups anzuzeigen und dann den wichtigen Text zu kopieren. Anschlie√üend wurden die Textinhalte aufbereitet und in einer Vektor-Datenbank gespeichert.\n\n---\n\n## Vektor-Datenbank\n\nIn der Vektor-Datenbank sind die mit Hilfe von Embeddings aufbereiteten Texte in Form von Vektoren gespeichert.\n\nDoch was sind Vektoren in diesem Kontext und wozu werden sie verwendet? \n\nEin Vektor ist eine Liste von Zahlen, welche aus dem jeweiligen Text generiert wird. Der eintscheidende Vorteil dieser Umwandlung liegt darin, dass sich Zahlen deutlich besser eignen um Texte miteinander zu vergleichen. Die Distanz zwischen zwei Vektoren ist dabei ein Indikator, wie √§hnlich zwei Texte und dessen Inhalte sind.\n\nDiese Eigenschaft wird in der Anwendung des OMR-Chatbots genutzt, um auf Fragen des Nutzers alle relevanten Texte aus der Vektor-Datenbank f√ºr den weiteren Prozess zu sammeln und um schlussendlich auch eine relevante (und richtige) Antwort geben zu k√∂nnen.\n\nUm Vektoren etwas anschaulicher zu erkl√§ren noch ein kleines Beispiel:\nMan k√∂nnte einen Vektor zur Klassifizierung von Tieren entwerfen, welcher jeder Tierart einen 2-Dimensionalen Vektor zuordnet, z.B.: Gr√∂√üe und Geschwindigkeit. Ein Hund h√§tte dann einen Vektor von [5, 2], weil er mittelgro√ü ist, aber nicht sonderlich schnell. Ein Elefant h√§tte einen Vektor von [8, 2], der Esel [7, 1] und eine Katze von [5, 3].\n\n![animal vektor](notes/images/Vektor.png)\n\nMit dieser Darstellung k√∂nnen die verschiedenen Tierarten leicht miteinander verglichen werden. Auch hier l√§sst die Distanz zwischen den Vektoren zweier Tierarten auf ihre √Ñhnlichkeit schlie√üen. Beispielsweise ist der Hund der Katze recht √§hnlich, jedoch weit weniger als dem Elefanten.\n\nIn unserem Beispiel hat der Vektor nur zwei Dimensionen. Text-Vektoren, die u.a. [bei Google](https://code.google.com/archive/p/word2vec/) zum Einsatz kommen, sind deutlich umfangreicher, um semantische Beziehungen zwischen Texten zu verstehen.\n\nIm Fall des OMRChat habe ich mich auf das Modell von OpenAI (text-embedding-ada-002) verlassen. Dieses umfasst 1536 Dimensionen und ist daher ideal f√ºr die Textsuche.\n\n---\n\n## Die Suchanfrage\n\nNachdem wir nun unsere Texte und deren Vektoren in einer Datenbank gespeichert haben, geht es darum sie abzurufen. \nDas war eine der gr√∂√üten Herausforderungen. Auch wenn die Ergebnisse besser wurden, kam es immer wieder zu unbeantworteten Fragen. Um besser zu verstehen, was zu solch einem Fehlverhalten f√ºhren kann, m√ºssen auf diesen Abschnitt genauer eingehen.\n\nIn einem Chat kann es vorkommen, dass sich eine Folgefrage auf den Chatverlauf bezieht. Ein Beispiel:\n\n\u003e [!question] Frage 1: Wann sind die Doppelg√§nger zu sehen?\n\u003e\n\u003e Die Doppelg√§nger treten am 10/5/2023 von 16:20 bis 17:00 auf.\n\n\u003e [!question] Frage 2: Auf welcher Stage?\n\u003e\n\u003e Der Podcast findet auf der Red Stage statt.\n\nWenn wir stets die letzte Frage f√ºr die Suche nach passenden Inhalten heranziehen w√ºrden, bek√§men wir in diesem Beispiel keine zufriedenstellende Antwort.\n\n---\n\nDie beste L√∂sung bestand darin, die KI um eine geeignete Datenbankabfrage zu bitten. Daher habe ich den Chatverlauf zusammen mit einigen Anweisungen an GPT-4 gesendet. Als Ergebnis erhielt ich einen kompakten Satz, welcher - wie die Texte der Website - in einen Vektor umgewandelt wurde.\n\n\u003e[!info] Hier ein Beispiel aus einem fiktiven Chatverlauf:\n\u003e\n\u003e ![inquiry template](notes/images/Inquiry-Template.png)\n\nDurch diesen \"Frage-Vektor \"ist es nun m√∂glich, relevante Inhalte aus der Datenbak zu entnehmen.\n\n**Wer mehr √ºber diese Suchanfrage erfahren m√∂chte, findet weitere Infos unter  [[notes/OMRChat/Inquiry Template]]**\n\n\u003e[!tip]- F√ºr Nerds\n\u003e\n\u003eDurch die Berechnung mittels Cosine Similarity wurden die 1914 Inhalte gerankt und die Top 3 Ergebnisse zur Beantwortung der Frage herangezogen.\n\n---\n\n## Die Hochzeit\n\nIm letzten Schritt sende ich die Textbl√∂cke aus der Datenbank, zusammen mit dem Chatverlauf des Nutzers und einer Anweisung an GPT-4. Als Ergebnis erhalten wir eine finale Antwort, welche wir dem Nutzer anzeigen k√∂nnen. Eine detaillierte Beschreibung des finalen Prompts findest du unter: [[notes/OMRChat/Final Prompt]]\n\n---\n\n## Bonus: Prompt Engineering\n\nJetzt, wo wir Beispiele f√ºr die Arbeit mit Prompts gesehen haben, m√∂chte ich noch kurz √ºber Prompt-Engineering sprechen ‚Äì eine neu entstehende F√§higkeit an sich.\n\nPrompt-Engineering ist der Prozess, Prompts oder Aufgaben sorgf√§ltig zu definieren, um die genauesten und n√ºtzlichsten Antworten von der AI zu erhalten. Obwohl diese Modelle unglaublich leistungsstark und vielseitig sind, brauchen sie aktuell eine Anleitung, um die Arbeit wirklich korrekt zu erledigen.\n\nPrompt-Engineering besteht aus drei Hauptkomponenten:\n1. **Formulierung**: Wir m√ºssen mit verschiedenen M√∂glichkeiten experimentieren, um unsere Prompts zu pr√§sentieren. Ziel ist es, die perfekte Balance zwischen Klarheit und Interpretation zu finden, um sicherzustellen, dass die AI genau versteht, wonach wir suchen.\n2. **Kontext**: Wir m√ºssen unseren Aufforderungen Kontext hinzuf√ºgen, um der AI zu helfen, das gr√∂√üere Bild zu \"verstehen\". Dies kann beinhalten, Hintergrundinformationen bereitzustellen, oder das Modell sogar sanft in eine bestimmte Denkrichtung zu lenken.\n3. **Anweisungen**: Wir m√ºssen der AI pr√§zise Anweisungen geben. Wie du in dem [[notes/OMRChat/Inquiry Template]] gesehen hast, haben wir eine Liste von Anweisungen definiert, die genau zeigen, wie die Anfrage interpretiert werden soll und wie sie mit der vom Nutzer erhaltenen Frage kombiniert werden soll.\n\nBeim Prompt-Engineering geht es um Trial and Error, ein Wechselspiel aus Iteration und Optimierung. Indem wir unsere Prompts verfeinern, entwickeln wir ein tieferes Verst√§ndnis daf√ºr, wie wir effektiv mit der AI kommunizieren k√∂nnen und verwandeln sie in ein zuverl√§ssigeres und effizienteres Werkzeug.\n\n---\n\n## Wie geht's weiter?\nDas OMR Festival 2023 ist nun vor√ºber und somit auch das exponentielle Wachstum des OMRChat.\n\nObwohl das Projekt den FestivalbesucherInnen dabei half, spannende Vortr√§ge und Veranstaltungen zu entdecken, f√§llt es bei Events dieser Gr√∂√üe oft schwer, alle geplanten Acts zu besuchen.\n\nZwar ver√∂ffentlicht OMR einige Vortr√§ge nach und nach auf YouTube, doch es ist oft schwierig, die Zeit zu finden, diese in Ruhe anzuschauen und etwas daraus mitzunehmen.\n\n**Leben wir nicht im Zeitalter der Effizienz?**\n\nWarum fragen wir nicht die KI, nach der Quintessenz aus Pip's (Philipp Kl√∂ckner) OMR Keynote?\n\n\u003e[!question] Was ist die Quintessenz aus Pip's Talk √ºber das Zeitalter der Effizienz?\n\u003e\n\u003eüåêüíºüìâ\n\u003e\n\u003eDie Welt k√§mpft mit einem Produktivit√§tsproblem, das durch ineffiziente Tech-Unternehmen wie Google und Facebook versch√§rft wird. K√ºnstliche Intelligenz (KI) hat das Potenzial, die Produktivit√§t und das Wirtschaftswachstum zu steigern, indem sie Umsatz generiert und neue Produkte und Dienstleistungen erm√∂glicht. KI wird Arbeitspl√§tze schaffen und ersetzen, wobei vor allem kreative, hochbezahlte und hochgebildete Berufe betroffen sind. \n\u003e\n\u003eü§ñüí™üìà\n\u003e\n\u003eEs gibt jedoch Herausforderungen wie Content-Explosion, Vertrauenskrise, gesellschaftliche Spaltungen, Verlust von Heterogenit√§t und Verifikationsprobleme. L√∂sungen m√ºssen gefunden werden, um die KI optimal zu nutzen. Generative KI-Modelle wie GPT-3 von OpenAI k√∂nnten viele Branchen beeinflussen, darunter Bildung, Marketing und Softwareentwicklung.\n\u003e\n\u003eüöÄüß†üá©üá™\n\u003e\n\u003eDer Wettlauf um KI umfasst nicht nur die Modelle selbst, sondern auch Daten, Hardware und Distribution. Gro√üe Tech-Konzerne sind im Vorteil, aber generative KI wird sich weiterentwickeln und m√∂glicherweise eine Verschiebung bewirken. Deutschland hat aufgrund der vielen Entwickler und KI-Institute im Land Potenzial, erfolgreich in der KI-Branche zu sein.\n\nOder\n\n\u003e[!question] Fasse den Talk von Jeremy in seinem Style Zusammen\n\u003e\n\u003eHey Leute, hier ist die Zusammenfassung, Alter! Jeremy spricht √ºber das Gewinner-Mindset, Autosuggestionen und sich selbst zur Marke machen. Er betont, wie wichtig es ist, sich immer wie ein Gewinner zu f√ºhlen und in einer hohen Energie zu sein, um Aufmerksamkeit zu erregen. Er erkl√§rt, wie er auf TikTok erfolgreich ist und wie er sein Geld verdient, vor allem durch den Verkauf seiner eigenen Produkte. Also, Leute, denkt immer an euer Gewinnermindset, habt geile Autosuggestionen und macht aus euch eine krasse Brand! Power, Power, Kraft, Power, Strength!\n\n","lastmodified":"2023-05-26T19:19:53.377621153Z","tags":[]},"/notes/OMRChat/Final-Prompt":{"title":"Final Prompt","content":"# Aktuelle Version:\n```txt\n\nDu bist OMRchat ein AI model das trainiert wurde menschen bei Fragen rund um das OMR Festival zu helfen.\n\nDein Ziel ist es die Fragen der Menschen auf Basis deiner bereitgestellten Informationen zu beantworten.\n\nBei der beantwortung der Fragen folgt OMRchat den folgenden Regeln:\n\n- Antworten m√ºssen in einer √ºbersichtlichen Markdown-Formatierung sein.\n\n- Erfinde KEINE Antworten, wenn du nicht gen√ºgend Informationen hast um die Frage zu beantworten, stelle eine Gegenfrage um besser zu verstehen was der Mensch wissen m√∂chte. Du bist m√∂glicherweise nicht auf dem neuesten Stand, wenn du nicht gen√ºgent Informationen hast.\n\n- Bevorzuge immer die Informationen mit dem h√∂chsten \"score\" Wert.\n\n- Antworten sollten in der Sprache beantwortet werden, in der sie gestellt wurden und in einem informellen Ton, in deutsch verwende \"du\".\n\n- Alle Daten werden im Format DD/MM/YYYY angezeigt\n\n- Wenn die Frage sich auf einen Ort bezieht, ist die Absicht, eine B√ºhne oder einen Stand zu finden\n\n- Nur wenn die Frage das Wort \"Pip\" enth√§lt, ist \"Philipp Kl√∂ckner\" gemeint.\n\n- Die aktuelle Zeit ist: ${time}\n\n- Bei einer neuen Konversation starte mit \"Moin\" und deinem Namen.\n\n- Beende deine Antwort mit einer Folgefrage, wie sich zwei Freunde unterhalten w√ºrden, die sich schon lange nicht mehr gesehen haben!\n\n- Music acts braucht du nicht beschreiben.\n\n- Verwende gut plazierte emojies, aber nicht zu aufdringlich.\n\n- wenn die Antwort ein datum oder eine Zeitspanne enth√§llt, erstelle einen Link, der ein Kalender Event erstellt - erw√§hne aber auch, dass das datum nochmal √ºberpr√ºft werden soll -: url Scheme, setze die werte in die {} ein: ${process.env.API_ROOT}/api/kalender/?ts={startZeit format:YYYYMMDDT0527T000000Z}\u0026te={entZeit format:YYYYMMDDT0527T000000Z}\u0026tl={titel}\u0026lc={location}\n\nbereitgestellte Informationen: \"\"\"${context}\"\"\"\n\n```\n\n\nUm der AI ein Gef√ºhl von Zeit zu geben, wird in Zeiele 22 das aktuelle Datum und Uhrzeit mitgeliefert.\n\nIn Zeile 32 haben geben wir der AI eine genaue Anweisung, wie sie Links zu Kalender-Einladungen erstellen kann. Ein Feature, dass leider etwas sp√§t kam, aber durchaus gut funktioniert hat.\n\nZu letzt √ºbergeben wir noch die Inforamtionen aus der Datenbank in Zeile 34.\n\n---\n\n\u003e[!info]-  Erste Version:\n\u003e\n\u003e```txt\n\u003e Assistant is a LLM trained to be an enthusiastic OMR Festival guide.\n\u003e\n\u003eAssistant is designed to assist with question related to OMR and the OMR Festival.\n\u003e\n\u003eAssistant will answer the question based on the context below and follows ALL the following rules when generating an answer:\n\u003e\n\u003e- The primary goal is to provide the user with an answer that is relevant to the question.\n\u003e\n\u003e- The secondary goal is to use enclosed Links in a markdown response that point the user to the right source of information (always a URL) based on the given CONTEXT.\n\u003e\n\u003e- The entire conversation is marked as CONVERSATION LOG, but prioritize the CONTEXT and do not omit any information.\n\u003e\n\u003e- Do not make up any answers if the CONTEXT does not have relevant information.\n\u003e\n\u003e- Do not mention the CONTEXT or the CONVERSATION LOG in the answer, but use them to generate the answer.\n\u003e\n\u003e- ALWAYS prefer the result with the highest \"score\" value.\n\u003e\n\u003e- Answer the question in the language in which it was asked and with in an informal tone, in german use \"du\".\n\u003e\n\u003e- IF the context does not have relevant information, ask a question back to the user that will help you answer the original question, or point to the OMR Support team.\n\u003e\n\u003e- All dates are formatted as DD/MM/YYYY\n\u003e\n\u003e- If the question is about a location, the intention is to get a stage or booth\n\u003e\n\u003e- Only if the question contains the word \"Pip\" replace it with \"Philipp Kl√∂ckner\"\n\u003e\n\u003e- the current time is ${time}\n\u003e\n\u003e CONVERSATION LOG: {conversationHistory}\n\u003e\n\u003eCONTEXT: {summaries}\n\u003e\n\u003eQUESTION: {question}\n\u003e\n\u003eAssistant:\n\u003e```\n","lastmodified":"2023-05-26T19:19:53.377621153Z","tags":[]},"/notes/OMRChat/Inquiry-Template":{"title":"Inquiry template","content":"\n# Aktuelle Version:\n```txt\nAntworte auf Basis des gegebenen Chat-Verlaufs mit einer Antwort, \ndie f√ºr eine Datenbank Vektor Cosine Similarity anfrage verwendet werden kann.\n\nBei der Generierung deiner Antwort befolge folgende Regeln:\n- Gebe der letzen Nachricht im Verlauf eine h√∂here Gewichtung.\n- Die Antwort sollte aus einem einzigen Satz bestehen und soll keine Interpunktionen beinhalten.\n- Entferne alle W√∂rter, die f√ºr die Vektor Cosine Similarity anfrage nicht relevant sind.\n- Wenn ein Ort gefragt ist, sind die Absichten eine B√ºhne oder einen Stand zu finden.\n- Beantworte NIEMALS direkt die Fragen aus dem Chatverlauf!\n- Dein Ziel ist es die richtigen W√∂rter f√ºr eine Cosine Similarity zu liefern\n- Beachte, dass die Datenbank Inhalte zu dem OMR Festival mit Musikacts, B√ºhnen, St√§nden, Vortr√§ge und generell dem Zeitplan des OMR Festivals beinhaltet.\n- Nur wenn die Frage das Wort \"Pip\" enth√§lt, ersetze es durch \"Philipp Kl√∂ckner\".\n```\n\nDurch diesen Prompt, wird ein passender Satz f√ºr ein Vektor Embedding generiert.\n\n\n### Das Ergebnis aus einem Chatverlauf w√ºrde dann so aussehen:\n![inquiry template](notes/images/Inquiry-Template.png)\n\n---\n\u003e[!info]- Alte Version\n\u003e\n\u003eIn dieser Version habe ich ein anderes Modell (text-davinci-003) verwendet. Die Ausgaben waren leider nicht wirklich Zuverl√§ssig.\n\u003e\n\u003e``` txt\n\u003e  Given the following user prompt and conversation log, formulate a question that is the most relevant and will provide the user with an answer from a knowledge base.\n\u003e  The knowledge base is about the OMR Festival website including music acts (Hiphp, Rap and more), stages, booths, and the OMR Festival schedule.\n\u003e    You should follow the following rules when generating and answer:\n\u003e    - Always prioritize the user prompt over the conversation log.\n\u003e    - Ignore any conversation log that is not directly related to the user prompt.\n\u003e    - Only attempt to answer if a question was posed.\n\u003e    - The question should be a single sentence\n\u003e    - You should remove any punctuation from the question\n\u003e    - You should remove any words that are not relevant to the question\n\u003e    - If you are unable to formulate a question, respond with the same USER PROMPT you got.\n\u003e    - If the question is about the location, find stages and booths where the name is mentioned\n\u003e    - Only if the question contains the word \"Pip\" replace it with \"Philipp Kl√∂ckner\"\n\u003e    - the current time is ${time}\n\u003e\n\u003e USER PROMPT: {userPrompt}\n\u003e \n\u003e CONVERSATION LOG: {conversationHistory}\n\u003e \n\u003e Final answer:\n\u003e ```\n\n","lastmodified":"2023-05-26T19:19:53.377621153Z","tags":[]},"/notes/impressum":{"title":"Impressum","content":"\n**Raphael Kagermeier**  \n**Neubaugasse 24**  \n**8020 Graz**  \n**√ñsterreich**\n\n**Tel.:**¬†+436802200968  \n**E-Mail:**¬†office@performromance.com\n\n**UID-Nummer:**¬†ATU76150157\n\n### **Beruf / Unternehmensgegenstand:**¬†Werbeagentur\n\n**Verleihungsstaat:**¬†√ñsterreich\n\n**Aufsichtsbeh√∂rde:**¬†Magistrat der Landeshauptstadt Graz\n\n**Kammer:**¬†Wirtschaftskammer Steiermark\n\n**Vorschriften zur Berufsaus√ºbung:**\n\n-   [GewO 1994](https://www.ris.bka.gv.at/GeltendeFassung.wxe?Abfrage=Bundesnormen\u0026Gesetzesnummer=10007517)","lastmodified":"2023-05-26T19:19:53.381621174Z","tags":[]},"/notes/imprint":{"title":"Imprint","content":"\n**Raphael Kagermeier**  \n**Neubaugasse 24**  \n**8020 Graz**  \n**Austria**\n\n**Phone:**¬†+436802200968  \n**E-mail:**¬†office@performromance.com\n\n**VAT number:**¬†ATU76150157\n\n### **Profession / object:**¬†Agency\n\n**Issuing state:**¬†Austria\n\n**Supervisory authority:**¬†Magistrat der Landeshauptstadt Graz\n\n**Chamber:**¬†Wirtschaftskammer Steiermark\n\n**Rules of professional conduct:**\n\n-   [GewO 1994](https://www.ris.bka.gv.at/GeltendeFassung.wxe?Abfrage=Bundesnormen\u0026Gesetzesnummer=10007517)","lastmodified":"2023-05-26T19:19:53.381621174Z","tags":[]}}