---
title: Erfahrungen und Erkentnisse auf dem Weg zum OMRChat.
---

![Hey Raphaelo](/notes/images/hey-raphaelo.png)
Mit einer einfachen Frage begannen f√ºnf intensive Tage, in denen ich viel √ºber Prompt Engineering und AI Chatbots lernte. Als mir Philipp Gl√∂ckler, einer der Hosts des [Doppelg√§nger Tech Talk Podcast](https://www.doppelgaenger.io/) schrieb, hatte ich nichts weiter als einen schlichten und wenig ansprechenden Prototypen eines Chatbots. Etwa 38 Stunden sp√§ter stand der OMRChat in seiner rudiment√§ren Form. In den darauffolgenden drei Tagen wurden weitere Optimierungen vorgenommen, sodass der Chatbot immer besser kommunizierte und Fragen beantworten konnte. In diesem Artikel erf√§hrst du, was ich dabei gelernt habe und wie das System funktioniert.

## Das Grundger√ºst
Um den Ablauf des Chatbots zu verstehen, sollten wir uns zuerst die grundlegende Struktur ansehen. Diese gliedert sich in drei Bereiche:

1. Daten und Indexierung
2. Datenbank und Ranking
3. Die Hochzeit

**Eine detaillierte Darstellung findest du in diesem Diagramm:**

>[!info]- Diagramm
>
> ![diagram](notes/images/OMRChat-diagram.png)

---

## Daten und Indexierung

Die erste Herausforderung bestand darin, alle relevanten Daten von Webseiten wie omr.com zu extrahieren. Daf√ºr entwickelte ich einen OMRCrawler, der einen Browser imitiert und versteht, wie der Content richtig abgerufen werden kann ‚Äì sprich: Auf die richtigen Buttons klicken, um Popups anzuzeigen und dann den wichtigen Text zu kopieren. Anschlie√üend wurden die Textinhalte aufbereitet und in einer Vektor-Datenbank gespeichert.

---

## Vektor-Datenbank

Was ist ein Vektor in diesem Kontext? 
Ein Textvektor, auch bekannt als Embedding, ist eine Methode zur mathematischen Darstellung von Text und seiner Bedeutung.

Zum Beispiel k√∂nnte ein Vektor zur Klassifizierung von Tieren in zwei Dimensionen dargestellt werden: ["Gr√∂√üe" und "Geschwindigkeit"]. Ein Hund h√§tte dann einen Vektor von [5, 3], weil er mittelgro√ü ist, aber nicht so schnell wie ein Gepard. Ein Elefant h√§tte einen Vektor von [8, 2], der Esel [7, 1] und eine Katze von [4, 3].

![animal vektor](notes/images/Vektor.png)

Bei dieser Darstellung ist erkennbar, dass die Katze dem Hund √§hnlicher als dem Esel ist.

In unserem Beispiel hat der Vektor nur zwei Dimensionen ["Gr√∂√üe" und "Geschwindigkeit"]. Text-Vektoren, die u.a. [bei Google](https://code.google.com/archive/p/word2vec/) zum Einsatz kommen, sind deutlich umfangreicher, um semantische Beziehungen zwischen W√∂rtern zu verstehen.

Im Fall des OMRChat habe ich mich auf das Modell von OpenAI (text-embedding-ada-002) verlassen. Dieses umfasst 1536 Dimensionen und ist daher ideal f√ºr die Textsuche.

Durch die Zahlen im Vektor, kann die Distanz der einzelnen Website-Texte zu der Frage des Nutzers berechnet werden.

---

## Die Suchanfrage

Nachdem wir nun unsere Texte und deren Vektoren in einer Datenbank gespeichert haben, geht es darum sie abzurufen. Das war eine der gr√∂√üten Herausforderungen. Auch wenn die Ergebnisse besser wurden, kam es immer wieder zu unbeantworteten Fragen. Um besser zu verstehen, was zu solch einem Fehlverhalten f√ºhren kann, m√ºssen auf diesen Abschnitt genauer eingehen.

In einem Chat kann es vorkommen, dass sich eine Folgefrage auf den Chatverlauf bezieht. Ein Beispiel:

> [!question] Frage 1: Wann sind die Doppelg√§nger zu sehen?
>
> Die Doppelg√§nger treten am 10/5/2023 von 16:20 bis 17:00 auf.

> [!question] Frage 2: Auf welcher Stage?
>
> Der Podcast findet auf der Red Stage statt.

Wenn wir stets die letzte Frage f√ºr die Suche nach passenden Inhalten heranziehen w√ºrden, bek√§men wir in diesem Beispiel keine zufriedenstellende Antwort.

---

---


Die beste L√∂sung bestand darin, die KI um eine geeignete Datenbankabfrage zu bitten. Daher habe ich den Chatverlauf zusammen mit einigen Anweisungen an GPT-4 gesendet. Als Ergebnis erhielt ich einen kompakten Satz, welcher - wie die Texte der Website - in einen Vektor umgewandelt wurde.

>[!info] Hier ein Beispiel aus einem fiktiven Chatverlauf:
>
> ![inquiry template](notes/images/Inquiry-Template.png)

Durch diesen "Frage-Vektor "ist es nun m√∂glich, relevante Inhalte aus der Datenbak zu entnehmen

**Wer mehr √ºber diese Suchanfrage erfahren m√∂chte, findet weitere Infos unter  [[notes/OMRChat/Inquiry Template]]**

>[!tip]- F√ºr Nerds
>
>Durch die Berechnung mittels Cosine Similarity wurden die 1914 Inhalte gerankt und die Top 3 Ergebnisse zur Beantwortung der Frage herangezogen.

---

## Die Hochzeit

Im letzten Schritt senden wir die Textbl√∂cke aus der Datenbank, zusammen mit dem Chatverlauf des Nutzers und einer Anweisung an GPT-4. Als Ergebnis erhalten wir eine finale Antwort, welche wir dem Nutzer anzeigen k√∂nnen. Eine detaillierte Beschreibung des finalen Prompts findest du unter: [[notes/OMRChat/Final Prompt]]

## Bonus: Prompt Engineering

Jetzt, wo wir Beispiele f√ºr die Arbeit mit Prompts gesehen haben, m√∂chte ich noch kurz √ºber Prompt-Engineering sprechen ‚Äì eine neu entstehende F√§higkeit an sich.

Prompt-Engineering ist der Prozess, Prompts oder Aufgaben sorgf√§ltig zu definieren, um die genauesten und n√ºtzlichsten Antworten von der AI zu erhalten. Obwohl diese Modelle unglaublich leistungsstark und vielseitig sind, brauchen sie aktuell eine Anleitung, um die Arbeit wirklich korrekt zu erledigen.

Prompt-Engineering besteht aus drei Hauptkomponenten:
1. **Formulierung**: Wir m√ºssen mit verschiedenen M√∂glichkeiten experimentieren, um unsere Prompts zu pr√§sentieren. Ziel ist es, die perfekte Balance zwischen Klarheit und Interpretation zu finden, um sicherzustellen, dass die AI genau versteht, wonach wir suchen.
2. **Kontext**: Wir m√ºssen unseren Aufforderungen Kontext hinzuf√ºgen, um der AI zu helfen, das gr√∂√üere Bild zu "verstehen". Dies kann beinhalten, Hintergrundinformationen bereitzustellen, oder das Modell sogar sanft in eine bestimmte Denkrichtung zu lenken.
3. **Anweisungen**: Wir m√ºssen der AI pr√§zise Anweisungen geben. Wie du in dem [[notes/OMRChat/Inquiry Template]] gesehen hast, haben wir eine Liste von Anweisungen definiert, die genau zeigen, wie die Anfrage interpretiert werden soll und wie sie mit der vom Nutzer erhaltenen Frage kombiniert werden soll.

Beim Prompt-Engineering geht es um Trial and Error, ein Wechselspiel aus Iteration und Optimierung. Indem wir unsere Prompts verfeinern, entwickeln wir ein tieferes Verst√§ndnis daf√ºr, wie wir effektiv mit der AI kommunizieren k√∂nnen und verwandeln sie in ein zuverl√§ssigeres und effizienteres Werkzeug.

## Wie geht's weiter?
Das OMR Festival 2023 ist nun vor√ºber und somit auch das exponentielle Wachstum des OMRChat.

Obwohl das Projekt den FestivalbesucherInnen dabei half, spannende Vortr√§ge und Veranstaltungen zu entdecken, f√§llt es bei Events dieser Gr√∂√üe oft schwer, alle geplanten Acts zu besuchen.

Zwar ver√∂ffentlicht OMR einige Vortr√§ge nach und nach auf YouTube, doch es ist oft schwierig, die Zeit zu finden, diese in Ruhe anzuschauen und etwas daraus mitzunehmen.

**Leben wir nicht im Zeitalter der Effizienz?**

Warum fragen wir nicht die KI, nach der Quintessenz aus Pip's (Philipp Kl√∂ckner) OMR Keynote?

>[!question] Was ist die Quintessenz aus Pip's Talk √ºber das Zeitalter der Effizienz?
>
>üåêüíºüìâ
>
>Die Welt k√§mpft mit einem Produktivit√§tsproblem, das durch ineffiziente Tech-Unternehmen wie Google und Facebook versch√§rft wird. K√ºnstliche Intelligenz (KI) hat das Potenzial, die Produktivit√§t und das Wirtschaftswachstum zu steigern, indem sie Umsatz generiert und neue Produkte und Dienstleistungen erm√∂glicht. KI wird Arbeitspl√§tze schaffen und ersetzen, wobei vor allem kreative, hochbezahlte und hochgebildete Berufe betroffen sind. 
>
>ü§ñüí™üìà
>
>Es gibt jedoch Herausforderungen wie Content-Explosion, Vertrauenskrise, gesellschaftliche Spaltungen, Verlust von Heterogenit√§t und Verifikationsprobleme. L√∂sungen m√ºssen gefunden werden, um die KI optimal zu nutzen. Generative KI-Modelle wie GPT-3 von OpenAI k√∂nnten viele Branchen beeinflussen, darunter Bildung, Marketing und Softwareentwicklung.
>
>üöÄüß†üá©üá™
>
>Der Wettlauf um KI umfasst nicht nur die Modelle selbst, sondern auch Daten, Hardware und Distribution. Gro√üe Tech-Konzerne sind im Vorteil, aber generative KI wird sich weiterentwickeln und m√∂glicherweise eine Verschiebung bewirken. Deutschland hat aufgrund der vielen Entwickler und KI-Institute im Land Potenzial, erfolgreich in der KI-Branche zu sein.

Oder

>[!question] Fasse den Talk von Jeremy in seinem Style Zusammen
>
>Hey Leute, hier ist die Zusammenfassung, Alter! Jeremy spricht √ºber das Gewinner-Mindset, Autosuggestionen und sich selbst zur Marke machen. Er betont, wie wichtig es ist, sich immer wie ein Gewinner zu f√ºhlen und in einer hohen Energie zu sein, um Aufmerksamkeit zu erregen. Er erkl√§rt, wie er auf TikTok erfolgreich ist und wie er sein Geld verdient, vor allem durch den Verkauf seiner eigenen Produkte. Also, Leute, denkt immer an euer Gewinnermindset, habt geile Autosuggestionen und macht aus euch eine krasse Brand! Power, Power, Kraft, Power, Strength!

Das alles und noch viel mehr